{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0352f87-237b-4510-a2ad-8ac017656bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b4d3e7-00e6-4c7a-9109-4e236637bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13eb125-4f7a-4168-885a-0270d92a829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# worldcloud\n",
    "import random\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a813b9-51e6-41ee-8e3d-90b8b2bda6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources (only needed once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc74807-851f-43db-971d-2f356c6fc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the datasets we used for the last notebook\n",
    "\n",
    "raw_path = '../data/olist_datasets/'\n",
    "\n",
    "df_customer = pd.read_csv(raw_path + 'olist_customers_dataset.csv')\n",
    "df_geolocation = pd.read_csv(raw_path + 'olist_geolocation_dataset.csv')\n",
    "df_orders = pd.read_csv(raw_path + 'olist_orders_dataset.csv')\n",
    "df_order_items = pd.read_csv(raw_path + 'olist_order_items_dataset.csv')\n",
    "df_order_payments = pd.read_csv(raw_path + 'olist_order_payments_dataset.csv')\n",
    "df_order_reviews = pd.read_csv(raw_path + 'olist_order_reviews_dataset.csv')\n",
    "df_products = pd.read_csv(raw_path + 'olist_products_dataset.csv')\n",
    "df_sellers = pd.read_csv(raw_path + 'olist_sellers_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871906b-4a63-4a9a-b250-91354a37dd93",
   "metadata": {},
   "source": [
    "# I - Sentiment analysis of customer reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f5ceb-b634-42a1-be04-c6c6751d1295",
   "metadata": {},
   "source": [
    "## A - Reminders on the Review dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0482e24-8d04-49dd-a3a1-0c0ce8e574ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that df_order_reviews is loaded\n",
    "\n",
    "df_order_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca108f21-1c12-4df4-b8b9-21bb6137ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distribution plot (dist plot) with seaborn on the review score\n",
    "\n",
    "# \"professional\" colors\n",
    "colors = ['#2C3E50', '#E74C3C', '#ECF0F1', '#3498DB', '#2ECC71', '#F1C40F', '#9B59B6']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create histogram with seaborn\n",
    "ax = sns.histplot(data=df_order_reviews, \n",
    "            x='review_score',\n",
    "            bins=5,\n",
    "            edgecolor='black',\n",
    "            stat='count')\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title('Distribution of Review Scores', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Review Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Ajuster les marges\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917a1d0-1c40-42df-8e6f-a0fc397fa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in review comments\n",
    "'your code'\n",
    "\n",
    "# Filter out rows with missing comments\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fc10e-c1b6-4d5f-ae80-24dc067b9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to categorize reviews as positive, neutral, or negative\n",
    "def categorize_sentiment(score):\n",
    "    '''if score is >=4 then good, if <3 then bad, else neutral'''\n",
    "\n",
    "    'your code'\n",
    "    \n",
    "    return\n",
    "\n",
    "# apply the function to the dataframe\n",
    " 'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fd1c1-5219-4457-a8bc-79d104cdaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sentiment distribution - how many reviews by categories?\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7a9ee-3c1a-469b-89b5-d3b5e7bd38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wordcloud\n",
    "\n",
    "# Create a wordcloud on orders with negative reviews only\n",
    "\n",
    "# Define a color function\n",
    "def color_func(word, font_size, position, orientation, random_state=42, **kwargs):\n",
    "    return random.choice(colors)\n",
    "\n",
    "# Example: Word cloud from review comments\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# every order\n",
    "#wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=color_func).generate(' '.join(df['review_comment_message'].dropna()))\n",
    "\n",
    "# only negative reviews\n",
    "#reviews_with_negative_comments = reviews_with_comments[reviews_with_comments.review_score < 3]\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=color_func)\n",
    "wordcloud.generate(' '.join(reviews_with_comments['review_comment_message'].dropna()))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title('Word Cloud of Review Comments', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7f32f-5d9d-441e-85bc-f42800f0eedb",
   "metadata": {},
   "source": [
    "## B - Text Preprocessing and conversion to numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a3330-bb10-4f9a-b4ac-90d46a409eca",
   "metadata": {},
   "source": [
    "### 1 - Cleaning a small sample of the data and looking at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d9c7b-d4ab-48b3-9f06-6f156dadf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new sample dataframe, that will be a sample of df_order_reviews\n",
    "# which only have non null review_comment_messages\n",
    "# which only contains review_id, review_score, review_comment_message\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643579ca-e07b-4f04-ab84-b7c0fe58ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new comment_clean column which makes the text LOWER (no uppercases)\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b829c-ea5e-44fb-bc05-06a65e02d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the special characters using a simple regex function\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54361fa7-9002-4461-98d7-3a4e34479c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text - meaning, isolate all words into a list, using the NLTK library, and another column - comment_clean_tokenized\n",
    "\n",
    "'your code'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae96a7-e3c5-43b4-b9f2-a2bcc25d68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then remove the stopwords using the portuguese library from NLTK\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4f303-e3e3-4d50-9fdf-24824eb00c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stemming to shorten the words as much as possible using another column - comment_clean_stemmed\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0bee1-ae27-4817-958b-6c3a34698bcb",
   "metadata": {},
   "source": [
    "### 2 - Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047dbf55-c2cb-4795-8117-eb7b26d21def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        'your code'\n",
    "        \n",
    "        # Remove special characters, numbers, and punctuation\n",
    "        'your code'\n",
    "        \n",
    "        # Tokenize the text\n",
    "        'your code'\n",
    "        \n",
    "        # Remove stopwords (Portuguese)\n",
    "        'your code'\n",
    "        \n",
    "        # Stemming\n",
    "        'your code'\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        'your code'\n",
    "        \n",
    "        return 'your code'\n",
    "    else:\n",
    "        return ''  # Return empty string for non-string inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34456f21-cee8-4575-b163-4c63614cd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the review comments\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fcf6d-121e-4803-b3c9-d2973129cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of original and processed comments\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5e9f7-2b84-41aa-9f43-fa795efa9157",
   "metadata": {},
   "source": [
    "### 3 - Final preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06168c58-5bf4-46e7-850c-be27addca044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef6766-4d6b-4404-8ebd-210c3aae3411",
   "metadata": {},
   "source": [
    "## C - Building a Simple Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd7c7b-39c9-477f-9bc0-8141812aa504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to convert text to a matrix of token counts\n",
    "count_vectorizer = CountVectorizer(max_features=5000)  # Limit to top 5000 features\n",
    "\n",
    "'your code'\n",
    "\n",
    "print(f\"Shape of training features: {X_train_counts.shape}\")\n",
    "print(f\"Shape of testing features: {X_test_counts.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659f706-edc0-4a63-98b6-55c16628b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding what we just did\n",
    "\n",
    "# Some computation to find an interesting extract to look at\n",
    "word_freq = X_train_counts.sum(axis=0).A1  # converting the matrix into an A1 array\n",
    "word_indices = word_freq.argsort()[-10:][::-1]  # 10 most frequent words\n",
    "top_feature_names = [count_vectorizer.get_feature_names_out()[i] for i in word_indices]\n",
    "\n",
    "# creating a sample with 10 most frequent words + 5 first reviews\n",
    "df_sample = pd.DataFrame(\n",
    "    X_train_counts[:5, word_indices].toarray(),\n",
    "    columns=top_feature_names\n",
    ")\n",
    "\n",
    "print(\"Displaying an extract of the bag-of-words matrix (5 first comments, 10 most frequent words):\")\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e76f8-d7ca-44d0-93ef-e63a6d26436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ae45a-44ed-4c68-b8c0-96b055413b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9240e7-b443-4c6a-bf6f-5c3f8bfe3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d6957-5d92-4aca-b7d1-36789b6630f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cfedc-2a69-412a-a5ba-0738e6af2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display confusion matrix\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb42b4-ba44-4bd1-bac6-e7292802cee1",
   "metadata": {},
   "source": [
    "## D - Building a More Advanced Model - Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e09821-43e2-47f6-96b8-7ced3704dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF Vectorizer for better feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae86e83-794e-413b-8c70-88f2cdc0c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa0139-08f2-4dbc-98b7-7aef639cd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "\n",
    "'your code'\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a111d47-b3a2-4262-9b1b-14fd599d20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8456f-cd28-4dfb-a271-4af9bf56cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display confusion matrix\n",
    "\n",
    "'your code'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=lr_classifier.classes_, \n",
    "            yticklabels=lr_classifier.classes_)\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984681e-831d-4418-b5fd-7a7fbddcfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Logistic Regression model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': tfidf_vectorizer.get_feature_names_out(),\n",
    "    'importance': lr_classifier.coef_.mean(axis=0)\n",
    "})\n",
    "\n",
    "# Sort by absolute importance\n",
    "feature_importance['abs_importance'] = abs(feature_importance['importance'])\n",
    "feature_importance = feature_importance.sort_values('abs_importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cde2b-faac-44e6-8dd9-74b47a619af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most important positive and negative words\n",
    "print(\"Top 10 words associated with positive sentiment:\")\n",
    "positive_features = feature_importance.sort_values('importance', ascending=False).head(10)\n",
    "print(positive_features[['feature', 'importance']])\n",
    "\n",
    "print(\"\\nTop 10 words associated with negative sentiment:\")\n",
    "negative_features = feature_importance.sort_values('importance', ascending=True).head(10)\n",
    "print(negative_features[['feature', 'importance']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc0c0b-8939-4d01-982d-6fe7215b0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "top_features = pd.concat([positive_features.head(15), negative_features.head(15)])\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features['importance']]\n",
    "\n",
    "'your code'\n",
    "\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e049b3-9d28-4001-b034-1d4de518d05d",
   "metadata": {},
   "source": [
    "## E - Rainforest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26c495-88dd-4195-8171-a13552e1a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer to understand how long the model will last\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a random forest model, while limiting the number of trees to make sure it doesn't run for too long\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,     # number of trees in the forest\n",
    "    max_depth=None,       # trees can be as deep (long) as possible\n",
    "    min_samples_split=2,  # minimum split number to build a node (2 trees min to build a node)\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # use all possible resources\n",
    ")\n",
    "\n",
    "# Use the model on the X_train TF-IDF data (same than the logistic regression)\n",
    "'your code'\n",
    "\n",
    "# Predictions on the train set\n",
    "'your code'\n",
    "\n",
    "# Compute execution time\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Random Forest training: {training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b50a9a-db24-46ee-9551-6d85f1464efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "'your code'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a518b-fe1d-42e8-b75f-ff021f2480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the classification report\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d91ab1-fa4b-48a4-bda5-a473914ea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the confusion matrix\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a2a20-98e3-4cf5-8353-516f2b99c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature importance of the Random Forest model\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea15c0-8a49-430c-bdf9-b9632c920c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most important features\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccace26-67e8-4816-b242-cabc114c3d7c",
   "metadata": {},
   "source": [
    "## F - Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d0779-9b18-46a5-9a46-83e661045caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare the performances of the 2 models\n",
    "models = ['Naive Bayes', 'Logistic Regression', 'Random Forest']\n",
    "accuracies = [accuracy_nb, accuracy_lr, accuracy_rf]\n",
    "\n",
    "'your code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83989e5d-1963-4ddc-8d1f-94eb176cc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the F1 score by class (f1_nb, f1_lr, f1_rf)\n",
    "\n",
    "'your code'\n",
    "\n",
    "# Create a dataframe for the visualization\n",
    "f1_df = pd.DataFrame({\n",
    "    'Naive Bayes': f1_nb,\n",
    "    'Logistic Regression': f1_lr,\n",
    "    'Random Forest': f1_rf\n",
    "}, index=rf_classifier.classes_)\n",
    "\n",
    "# Visualize F1 scores by classes\n",
    "\n",
    "'your code'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a5b42-a6ea-4502-8322-93ed3833f854",
   "metadata": {},
   "source": [
    "## G - Example use case: predicting new comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13014c2d-8eb5-4022-8028-5f8fed78027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to predict sentiment for new reviews\n",
    "def predict_sentiment(review_text, vectorizer, model):\n",
    "    # Preprocess the review\n",
    "    processed_review = preprocess_text(review_text)\n",
    "    # Vectorize the review\n",
    "    review_vector = vectorizer.transform([processed_review])\n",
    "    # Predict the sentiment\n",
    "    sentiment = model.predict(review_vector)[0]\n",
    "    # Get prediction probabilities\n",
    "    proba = model.predict_proba(review_vector)[0]\n",
    "    # Return the sentiment and confidence\n",
    "    return sentiment, proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220aa0c3-46af-443b-8405-0f6abceef8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example reviews to test\n",
    "example_reviews = [\n",
    "    \"O produto é excelente, superou minhas expectativas!\",  # Positive\n",
    "    \"Entrega foi feita no prazo, mas o produto não é tão bom quanto esperava.\",  # Neutral\n",
    "    \"Péssimo produto, chegou com defeito e o atendimento ao cliente foi horrível.\"  # Negative\n",
    "]\n",
    "\n",
    "# Predict sentiment for example reviews\n",
    "print(\"Predicting sentiment for example reviews:\")\n",
    "for i, review in enumerate(example_reviews):\n",
    "    'your code here'\n",
    "    print(f\"\\nExample {i+1}: {review}\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(f\"Confidence: {max(proba):.2f}\")\n",
    "    print(f\"Probabilities: {dict(zip(lr_classifier.classes_, proba))}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c150d3-4bdd-4646-8514-091b3e600596",
   "metadata": {},
   "source": [
    "# II - Delivery prediction (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0838558-ba0b-4b7a-ba5b-c4bad1b6ccbb",
   "metadata": {},
   "source": [
    "## A - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496fb11-5c89-43eb-9c87-0bc24abb573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the merged dataframe from previous parts\n",
    "# If not already done, we need to merge the necessary dataframes\n",
    "if 'df' not in globals():\n",
    "    # Load required datasets\n",
    "    df_orders = pd.read_csv(raw_path + 'olist_orders_dataset.csv')\n",
    "    df_customers = pd.read_csv(raw_path + 'olist_customers_dataset.csv')\n",
    "    df_order_items = pd.read_csv(raw_path + 'olist_order_items_dataset.csv')\n",
    "    df_products = pd.read_csv(raw_path + 'olist_products_dataset.csv')\n",
    "    \n",
    "    # Merge datasets\n",
    "    df = df_orders.merge(df_customers, on='customer_id')\n",
    "    df = df.merge(df_order_items, on='order_id')\n",
    "    df = df.merge(df_products, on='product_id')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40206d9-080c-4d5c-a05c-2a6b2725e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "date_columns = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
    "                'order_estimated_delivery_date']\n",
    "\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "\n",
    "# Calculate delivery time in days\n",
    "df['actual_delivery_time'] = (df['order_delivered_customer_date'] - \n",
    "                             df['order_purchase_timestamp']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Calculate if the delivery was delayed (1) or not (0)\n",
    "df['estimated_delivery_time'] = (df['order_estimated_delivery_date'] - \n",
    "                                df['order_purchase_timestamp']).dt.total_seconds() / (24 * 3600)\n",
    "df['is_delayed'] = (df['actual_delivery_time'] > df['estimated_delivery_time']).astype(int)\n",
    "\n",
    "# Calculate time to carrier in days\n",
    "df['time_to_carrier'] = (df['order_delivered_carrier_date'] - \n",
    "                        df['order_purchase_timestamp']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Filter out rows with missing delivery dates (canceled orders, etc.)\n",
    "delivery_df = df.dropna(subset=['order_delivered_customer_date', 'order_delivered_carrier_date'])\n",
    "\n",
    "delivery_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd295c-6239-402b-8de4-803631ee3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='is_delayed', data=delivery_df, palette='viridis')\n",
    "plt.title('Distribution of Delayed vs On-time Deliveries', fontsize=16)\n",
    "plt.xlabel('Is Delayed (1 = Yes, 0 = No)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks([0, 1], ['On-time', 'Delayed'])\n",
    "for i, count in enumerate(delivery_df['is_delayed'].value_counts()):\n",
    "    plt.text(i, count + 100, f\"{count} ({count/len(delivery_df):.1%})\", \n",
    "             ha='center', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2ca9f-f690-46ae-82ba-847c01c68f61",
   "metadata": {},
   "source": [
    "## B - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fd836-62de-4029-be17-180c9b140ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_df = delivery_df.copy()\n",
    "\n",
    "# Extract temporal features\n",
    "model_df['purchase_hour'] = model_df['order_purchase_timestamp'].dt.hour\n",
    "model_df['purchase_day'] = model_df['order_purchase_timestamp'].dt.day\n",
    "model_df['purchase_month'] = model_df['order_purchase_timestamp'].dt.month\n",
    "model_df['purchase_year'] = model_df['order_purchase_timestamp'].dt.year\n",
    "model_df['purchase_dayofweek'] = model_df['order_purchase_timestamp'].dt.dayofweek\n",
    "model_df['purchase_weekend'] = (model_df['purchase_dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# Calculate distance between customer and seller (using zip code prefix as a proxy)\n",
    "model_df['zip_distance'] = abs(model_df['customer_zip_code_prefix'] - model_df['seller_zip_code_prefix'])\n",
    "\n",
    "# Calculate price per weight\n",
    "model_df['price_per_weight'] = model_df['price'] / model_df['product_weight_g'].replace(0, 0.1)\n",
    "\n",
    "# Create product volume feature\n",
    "model_df['product_volume'] = (model_df['product_length_cm'] * \n",
    "                             model_df['product_height_cm'] * \n",
    "                             model_df['product_width_cm'])\n",
    "\n",
    "# Handle infinite values\n",
    "model_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Display the first few rows of the engineered features\n",
    "print(\"Sample of engineered features:\")\n",
    "model_df[['purchase_hour', 'purchase_day', 'purchase_month', 'purchase_year', \n",
    "                'purchase_dayofweek', 'purchase_weekend', 'zip_distance', \n",
    "                'price_per_weight', 'product_volume']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba36e4d-b01e-434a-8c7d-32e60569da7b",
   "metadata": {},
   "source": [
    "## C - Exploratory Data Analysis for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4504a8-e1c8-462f-bb72-9851c9989975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation between features and delivery time with a correlation matrix\n",
    "\n",
    "'your code here'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec5a22-f4c1-4d8d-a2e0-3b1d11babd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "categorical_features = ['customer_state', 'seller_state', 'product_category_name']\n",
    "\n",
    "# compute the average delivery time for each of the categorical feature with a bar chart\n",
    "\n",
    "'your code here'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d9019-ec8c-4e6e-841e-313ee386582e",
   "metadata": {},
   "source": [
    "## D - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8e1f2-2e79-43c3-85a4-99f6c11faa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features based on correlation analysis and domain knowledge\n",
    "selected_numeric_features = ['freight_value', 'price', 'product_weight_g', \n",
    "                            'product_volume', 'zip_distance', 'time_to_carrier',\n",
    "                            'purchase_month', 'purchase_dayofweek']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d5078-73f8-4961-b50a-5ae2bc99d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature and target variables\n",
    "X_numeric = model_df[selected_numeric_features]\n",
    "X_categorical = model_df[selected_categorical_features]\n",
    "X_combined = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "\n",
    "# For regression task (predicting delivery time)\n",
    "y_regression = model_df['actual_delivery_time']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_combined, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a4194-ec96-43c4-9439-6364ddff7c3a",
   "metadata": {},
   "source": [
    "## E - Building the Regression Model (Predicting Delivery Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89aa0dc-05f2-4dca-ad44-2ea79c7685bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numeric features\n",
    "\n",
    "'your code here'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484af5d-b0fb-4d40-8fe1-5785c7fbe673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression Pipeline\n",
    "\n",
    "'your code here'\n",
    "\n",
    "# Train and evaluate Linear Regression\n",
    "\n",
    "'your code here'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f3fdd-3e14-4f08-848a-b51985e0dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on your linear regression\n",
    "\n",
    "'your code here'\n",
    "\n",
    "# Evaluate the model\n",
    "mae_lr = 'your code here'\n",
    "rmse_lr = 'your code here'\n",
    "r2_lr = 'your code here'\n",
    "\n",
    "print(f\"Linear Regression - MAE: {mae_lr:.2f} days\")\n",
    "print(f\"Linear Regression - RMSE: {rmse_lr:.2f} days\")\n",
    "print(f\"Linear Regression - R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08f062-047d-4d37-8d90-bd843b86a2fe",
   "metadata": {},
   "source": [
    "the R² should be about 0.40, which is not a good number. Can you do better with a Random Forest model, or any other model? \n",
    "\n",
    "Objective is to get a R² > 0.45!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769b6d5-8e84-472d-a9d0-72321867ff4f",
   "metadata": {},
   "source": [
    "## F - Building a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcef83a-528b-4692-a0c7-aa5bd5df9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'your code here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09ba80-7345-4233-817a-6cb7f0247840",
   "metadata": {},
   "source": [
    "### G - Building a K-Nearest Neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e58aa9-c84f-4feb-9a61-2480340cd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "'your code here'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
